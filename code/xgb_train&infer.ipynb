{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0bc156-54ac-48a6-9bb9-7875c40185d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "trn_file = '../input/round2_train_X_extracted_features6.csv'\n",
    "tst_file = '../input/round2_test_X_extracted_features6.csv'\n",
    "# 读取数据\n",
    "def load_data():\n",
    "    train_data = pd.read_csv(trn_file)\n",
    "    \n",
    "    tmp_train_labels = pd.read_csv('../input/label.csv')\n",
    "    train_labels = train_data[['file_name']].copy()\n",
    "    train_labels = train_labels.merge(tmp_train_labels,on='file_name',how='left')\n",
    "    train_labels = train_labels[['label_id']].copy()\n",
    "    \n",
    "    test_data = pd.read_csv(tst_file)\n",
    "    \n",
    "    # return train_data.drop(['file_name'],axis=1)[features], train_labels, test_data.drop(['file_name'],axis=1)[features]\n",
    "    return train_data.drop(['file_name'],axis=1), train_labels, test_data.drop(['file_name'],axis=1)\n",
    "# 数据预处理\n",
    "def preprocess_data(train_data, train_labels, test_data):\n",
    "    # 确保数据类型正确\n",
    "    train_data = train_data.astype(float)\n",
    "    test_data = test_data.astype(float)\n",
    "    \n",
    "    # 处理缺失值\n",
    "    train_data.fillna(train_data.mean(), inplace=True)\n",
    "    test_data.fillna(test_data.mean(), inplace=True)\n",
    "\n",
    "    train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    test_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    test_data[test_data > np.finfo(np.float32).max] = 0\n",
    "    \n",
    "    return train_data, train_labels, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "578ddfae-df9b-4f13-9fdc-b8a7f622a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_with_cv(train_data, train_labels, test_data, n_splits=5):\n",
    "\n",
    "    train_labels = train_labels.label_id.values\n",
    "    # 计算类别权重来处理长尾分布\n",
    "    classes = np.unique(train_labels)\n",
    "    class_weights = dict()\n",
    "    n_samples = len(train_labels)\n",
    "    \n",
    "    for c in classes:\n",
    "        c_count = np.sum(train_labels == c)\n",
    "        class_weights[c] = n_samples / (len(classes) * c_count)\n",
    "\n",
    "    # XGBoost参数设置\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',  # 多分类\n",
    "        'num_class': len(classes),\n",
    "        'max_depth': 15,  # 控制树的深度，防止过拟合\n",
    "        'min_child_weight': 5,  # 增大这个值有助于处理类别不平衡\n",
    "        'gamma': 0.15,  # 控制是否进一步分裂\n",
    "        'subsample': 0.9,  # 随机采样，防止过拟合\n",
    "        'colsample_bytree': 0.9,  # 特征采样\n",
    "        'eta': 0.01,  # 较小的学习率\n",
    "        # 'scale_pos_weight': 1,  # 类别不平衡时的缩放因子\n",
    "        'seed': 1001\n",
    "    }\n",
    "    params[\"device\"] = \"cuda\"\n",
    "    params[\"tree_method\"] = \"hist\"\n",
    "    # 准备交叉验证\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    oof_predictions = np.zeros((len(train_data), len(classes)))\n",
    "    test_predictions = np.zeros((len(test_data), len(classes)))\n",
    "    \n",
    "    # 早停设置\n",
    "    early_stopping_rounds = 80\n",
    "\n",
    "    # 开始交叉验证训练\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train_data, train_labels)):\n",
    "        print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "        fold_model=f'xgb_model_fold{fold + 1}.pkl'\n",
    "                   \n",
    "        X_train, X_valid = train_data.iloc[train_idx,:], train_data.iloc[valid_idx,:]\n",
    "        y_train, y_valid = train_labels[train_idx], train_labels[valid_idx]\n",
    "        \n",
    "        # 计算样本权重\n",
    "        sample_weights = np.array([class_weights[label] for label in y_train])\n",
    "        \n",
    "        # 准备数据集\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, weight=sample_weights) \n",
    "        dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "        dtest = xgb.DMatrix(test_data)\n",
    "        \n",
    "        # 设置评估指标\n",
    "        def micro_f1_eval(preds, dtrain):\n",
    "            labels = dtrain.get_label()\n",
    "            preds = np.argmax(preds.reshape(len(labels), -1), axis=1)\n",
    "            score = f1_score(labels, preds, average='micro')\n",
    "            return 'micro_f1', score\n",
    "            \n",
    "        if not os.path.exists(fold_model): \n",
    "            # 训练模型\n",
    "            model = xgb.train(\n",
    "                params,\n",
    "                dtrain,\n",
    "                num_boost_round=1000000,\n",
    "                evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "                early_stopping_rounds=early_stopping_rounds,\n",
    "                # feval=micro_f1_eval,\n",
    "                verbose_eval=100\n",
    "            )\n",
    "            joblib.dump(model, fold_model)\n",
    "        else:\n",
    "            model = joblib.load(fold_model)\n",
    "        \n",
    "        # 保存验证集预测\n",
    "        oof_predictions[valid_idx] = model.predict(dvalid)\n",
    "        \n",
    "        # 累积测试集预测\n",
    "        test_predictions += model.predict(dtest) / n_splits\n",
    "        \n",
    "        # 打印当前折的性能\n",
    "        valid_preds = np.argmax(oof_predictions[valid_idx], axis=1)\n",
    "        fold_score = f1_score(y_valid, valid_preds, average='micro')\n",
    "        print(f\"Fold {fold + 1} - Micro F1: {fold_score:.4f}\")\n",
    "        \n",
    "    # 计算整体性能\n",
    "    final_predictions = np.argmax(oof_predictions, axis=1)\n",
    "    final_score = f1_score(train_labels, final_predictions, average='micro')\n",
    "    print(f\"\\nOverall CV Micro F1: {final_score:.4f}\")\n",
    "    \n",
    "    return oof_predictions, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff0866-512a-4535-b191-f6aaa94d5b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据...\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "print(\"加载数据...\")\n",
    "train_data, train_labels, test_data = load_data()\n",
    "\n",
    "# 预处理数据\n",
    "print(\"预处理数据...\")\n",
    "train_data, train_labels, test_data = preprocess_data(train_data, train_labels, test_data)\n",
    "\n",
    "# 训练和评估模型\n",
    "print(\"开始交叉验证训练...\")\n",
    "oof_preds, test_preds = train_xgboost_with_cv(train_data, train_labels, test_data)\n",
    "\n",
    "print(\"\\n模型训练和预测完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceddf19f-fe27-430b-80fa-9310cec0211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_post = test_preds**(1/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42488a5e-9850-4ad8-ba6f-628e17c8b5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "label_to_id = joblib.load('../code/label_to_id.pkl')\n",
    "id_to_label = {}\n",
    "for k, v in label_to_id.items():\n",
    "    id_to_label[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f85327-85b2-4078-8fac-9b6d994c1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas_df = pd.DataFrame(test_preds_post)\n",
    "probas_df['file_name'] = pd.read_csv(tst_file)[['file_name']]\n",
    "\n",
    "sub_df = probas_df.groupby('file_name').mean().reset_index()\n",
    "sub_df['label_id'] = sub_df.drop([\"file_name\"],axis=1).apply(lambda x:np.argmax(x), axis=1)\n",
    "\n",
    "sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e51629-ab58-4b7e-86cf-83cb10d99185",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['label_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2cae2-e8dc-498d-a044-749a06ec5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['reconstructed_label'] = sub_df['label_id'].map(id_to_label)\n",
    "# 将合并标签拆分为原始的 94 列\n",
    "reconstructed_labels = sub_df['reconstructed_label'].str.split('_', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14cf97a-8276-4424-bcae-5b22c2025d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.concat([sub_df[['file_name']], reconstructed_labels], axis=1)\n",
    "out_df.columns = pd.read_csv('../input/train_y_v0.1.0.csv').columns\n",
    "out_df = out_df.replace('-1', 0.1)\n",
    "out_df = out_df.replace( '1', 0.9)\n",
    "out_df = out_df.replace( '0',  0)\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4a7b6-5c97-4a02-adc0-2bdd7bcea870",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('../subs/baseline_xgb_cv5_06.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0fdd6-ecae-44f4-99d0-440a4ebdb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f7e37-af08-439a-a19c-f9d16ea2b3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret-optuna",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
