{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b469240d-a56c-41dd-97dc-acfdba17412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import find_peaks\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略所有警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262881e7-0834-4f90-89cd-0e998dffd592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_by_interval(df, time_column, interval_days):\n",
    "    nanoseconds_per_week = interval_days * 24 * 60 * 60 * 1e9\n",
    "    df['w_th'] = df['t'].astype('int64') // nanoseconds_per_week\n",
    "\n",
    "    sub_dfs = []\n",
    "    for w_th in df['w_th'].unique():\n",
    "        sub_df = df[df['w_th']==w_th].copy()\n",
    "        if len(sub_df)>=interval_days:\n",
    "            sub_dfs.append(sub_df)\n",
    "    return sub_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680c5cf-220a-4008-85a2-fda52d5268b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('../input/train_y_v0.1.0.csv')\n",
    "\n",
    "# 1. 将每行的 94 列标签合并为一个字符串\n",
    "labels_df['combined_label'] = labels_df[labels_df.columns.tolist()[1:]].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "# 2. 创建从合并标签到唯一 ID 的映射\n",
    "label_to_id = {label: idx for idx, label in enumerate(labels_df['combined_label'].unique())}\n",
    "\n",
    "# 3. 将合并标签映射为唯一 ID\n",
    "labels_df['label_id'] = labels_df['combined_label'].map(label_to_id)\n",
    "\n",
    "joblib.dump(label_to_id,'label_to_id.pkl')\n",
    "\n",
    "new_labels_df = labels_df[['filename','label_id']].copy()\n",
    "new_labels_df.columns = ['file_name','label_id']\n",
    "new_labels_df.to_csv('../input/label.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e780a51-9bcc-4ded-9bb5-cd5026710e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis, tvar, tstd\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import find_peaks\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定义特征提取函数\n",
    "def extract_features(sequence, pre_fix, is_v_seq=False, more_features=False):\n",
    "    \"\"\"\n",
    "    提取时序数据的特征\n",
    "    :param sequence: 一维时序数据 (np.array)\n",
    "    :return: 特征字典\n",
    "    \"\"\"\n",
    "    warnings.filterwarnings(\"ignore\") \n",
    "    features = {}\n",
    "\n",
    "    # 1. 基本统计特征\n",
    "    features['mean'] = np.mean(sequence)\n",
    "    features['std']  = tstd(sequence)\n",
    "    features['min']  = np.min(sequence)\n",
    "    features['max']  = np.max(sequence)\n",
    "    features['median'] = np.median(sequence)\n",
    "    features['skewness'] = skew(sequence)\n",
    "    features['kurtosis'] = kurtosis(sequence)\n",
    "    features['range'] = features['max'] - features['min']\n",
    "    features['q1']  = np.percentile(sequence, 25)\n",
    "    features['q3']  = np.percentile(sequence, 75)\n",
    "    features['iqr'] = features['q3'] - features['q1']\n",
    "    \n",
    "    if is_v_seq==True:\n",
    "        features['mad'] = np.mean(np.abs(sequence - np.mean(sequence)))\n",
    "        if np.mean(sequence)!=0:\n",
    "            features['cv'] =  tstd(sequence) / np.mean(sequence)\n",
    "        else:\n",
    "            features['cv'] =  0\n",
    "    \n",
    "        if features['cv'] != 0:\n",
    "            features['reciprocal_cv'] = 1 / features['cv']\n",
    "        else:\n",
    "            features['reciprocal_cv'] = 0\n",
    "    \n",
    "        # 2. 时域特征\n",
    "        features['zero_crossings'] = np.sum(np.diff(np.sign(sequence)) != 0)\n",
    "        features['autocorrelation'] = np.correlate(sequence, sequence, mode='full')[len(sequence) - 1]\n",
    "        features['energy'] = np.sum(sequence ** 2)\n",
    "        # 均方根 (RMS)\n",
    "        features['rms'] = np.sqrt(np.mean(np.square(sequence)))\n",
    "        # 能量\n",
    "        features['energy'] = np.sum(np.square(sequence))\n",
    "        features['energy_rate'] = features['energy'] / len(sequence)\n",
    "        # 过零率\n",
    "        features['zero_crossing_rate'] = np.sum(np.diff(np.sign(sequence)) != 0) / len(sequence)\n",
    "        # 不过零率\n",
    "        features['non_zero_crossing_rate'] = 1 - np.sum(np.diff(np.sign(sequence)) != 0) / len(sequence)\n",
    "        # 绝对均值\n",
    "        features['mean_absolute_value'] = np.mean(np.abs(sequence))\n",
    "        \n",
    "        if features['mean_absolute_value']!=0:\n",
    "            # 形状因子\n",
    "            features['shape_factor']   = features['rms'] / features['mean_absolute_value']\n",
    "            # 脉冲因子\n",
    "            features['impulse_factor'] = np.max(np.abs(sequence)) / features['mean_absolute_value']\n",
    "        else:\n",
    "            features['shape_factor']   = 0\n",
    "            features['impulse_factor'] = 0\n",
    "        if features['rms']!=0:\n",
    "            # 峰值因子\n",
    "            features['crest_factor'] = np.max(np.abs(sequence)) / features['rms']\n",
    "        else:\n",
    "            features['crest_factor'] = 0\n",
    "        if np.mean(np.sqrt(np.abs(sequence))) ** 2!=0:\n",
    "            # 裕度因子\n",
    "            features['margin_factor'] = np.max(np.abs(sequence)) / np.mean(np.sqrt(np.abs(sequence))) ** 2\n",
    "        else:\n",
    "            features['margin_factor'] = 0\n",
    "\n",
    "        # 3. 频域特征\n",
    "        fft_values = np.abs(fft(sequence))\n",
    "        features['fft_mean']= np.mean(fft_values)\n",
    "        features['fft_std'] = tstd(fft_values)\n",
    "        features['fft_max'] = np.max(fft_values)\n",
    "        features['fft_min'] = np.min(fft_values)\n",
    "        features['fft_dominant_freq'] = np.argmax(fft_values)\n",
    "        features['fft_skewness'] = skew(fft_values)\n",
    "        features['fft_kurtosis'] = kurtosis(fft_values)\n",
    "    \n",
    "        # # 4. 峰值特征\n",
    "        peaks, _ = find_peaks(sequence)\n",
    "        peak_intervals = np.diff(peaks)\n",
    "        features['num_peaks'] = len(peaks)\n",
    "        if len(peaks) > 0:\n",
    "            features['peak_mean'] = np.mean(sequence[peaks])\n",
    "            features['peak_std']  = tstd(sequence[peaks])\n",
    "        else:\n",
    "            features['peak_mean'] = 0\n",
    "            features['peak_std']  = 0\n",
    "    \n",
    "    if more_features==True:\n",
    "        if len(peaks) > 0:\n",
    "            features['num_peaks_ratio'] = len(peaks) / len(sequence)\n",
    "            features['peak_max'] = np.max(sequence[peaks])\n",
    "            features['peak_min'] = np.min(sequence[peaks])\n",
    "            features['peak_iqr'] = features['peak_max'] - features['peak_min']\n",
    "            \n",
    "            features['peak_skewness'] = skew(sequence[peaks])\n",
    "            features['peak_kurtosis'] = kurtosis(sequence[peaks])\n",
    "            features['peak_range'] = features['max'] - features['min']\n",
    "            features['peak_q1']  = np.percentile(sequence[peaks], 25)\n",
    "            features['peak_q3']  = np.percentile(sequence[peaks], 75)\n",
    "            features['peak_iqr'] = features['peak_q3'] - features['peak_q1']\n",
    "            features['peak_mad'] = np.mean(np.abs(sequence[peaks] - np.mean(sequence[peaks])))\n",
    "        \n",
    "        else:\n",
    "            features['num_peaks_ratio'] = 0\n",
    "            features['peak_max'] = 0\n",
    "            features['peak_min'] = 0\n",
    "            features['peak_iqr'] = 0\n",
    "            features['peak_skewness'] = 0\n",
    "            features['peak_kurtosis'] = 0\n",
    "            features['peak_range'] = 0\n",
    "            features['peak_q1']  = 0\n",
    "            features['peak_q3']  = 0\n",
    "            features['peak_iqr'] = 0\n",
    "            features['peak_mad'] = 0\n",
    "        \n",
    "        if len(peak_intervals) > 0:   \n",
    "            features['peak_intervals_max'] = np.max(peak_intervals)\n",
    "            features['peak_intervals_min'] = np.min(peak_intervals)\n",
    "            features['peak_intervals_std'] = tstd(peak_intervals)\n",
    "            features['peak_intervals_mean']= np.mean(peak_intervals)\n",
    "            features['peak_intervals_range'] = features['peak_intervals_max'] - features['peak_intervals_min']\n",
    "    \n",
    "            features['peak_intervals_skewness'] = skew(peak_intervals)\n",
    "            features['peak_intervals_kurtosis'] = kurtosis(peak_intervals)\n",
    "            \n",
    "        else:   \n",
    "            features['peak_intervals_max'] = 0\n",
    "            features['peak_intervals_min'] = 0\n",
    "            features['peak_intervals_std'] = 0\n",
    "            features['peak_intervals_mean']= 0\n",
    "            features['peak_intervals_range']    = 0\n",
    "            features['peak_intervals_skewness'] = 0\n",
    "            features['peak_intervals_kurtosis'] = 0\n",
    "    out_features = {}\n",
    "    for k,v in features.items():\n",
    "        out_features[f'{pre_fix}_{k}'] = v\n",
    "    \n",
    "    return out_features\n",
    "\n",
    "def process_file(file_path):\n",
    "    warnings.filterwarnings(\"ignore\") \n",
    "    pkl_data = pd.DataFrame(joblib.load(file_path))\n",
    "    pkl_data['t_scds'] = pkl_data['t'].dt.total_seconds()\n",
    "    pkl_data['v_diff'] = pkl_data['v'] - pkl_data['v'] .shift(1)\n",
    "    pkl_data['t_diff'] = pkl_data['t_scds'] - pkl_data['t_scds'].shift(1)\n",
    "    \n",
    "    # 按每周拆分\n",
    "    sub_dfs = split_dataframe_by_interval(pkl_data, time_column='t', interval_days=1)\n",
    "    # 如果不够一周时间需要检查是否有n条数据\n",
    "    if not sub_dfs:\n",
    "        sub_dfs = [pkl_data]\n",
    "    \n",
    "    sub_df_features = []\n",
    "    for tmp_df in sub_dfs:\n",
    "        sequence_tmp1 = tmp_df['v'].values\n",
    "        sequence_tmp2 = tmp_df['v_diff'].values\n",
    "        sequence_tmp3 = tmp_df['t_diff'].values\n",
    "        features1 = extract_features(sequence_tmp1, pre_fix='v', is_v_seq=True, more_features=True)\n",
    "        features2 = extract_features(sequence_tmp2, pre_fix='v_diff', is_v_seq=False, more_features=False)\n",
    "        features3 = extract_features(sequence_tmp3, pre_fix='t_diff', is_v_seq=False, more_features=False)\n",
    "\n",
    "        features = {}\n",
    "        for tmp_features_dict in [features1,features2,features3]:\n",
    "            for k,v in tmp_features_dict.items():\n",
    "                features[k] = v\n",
    "        \n",
    "        features['week_points_count'] = len(tmp_df)\n",
    "        features['week_points_count_ratio'] = len(tmp_df) / len(sub_dfs[0])\n",
    "        features['total_weeks'] = len(sub_dfs)\n",
    "        features['file_name'] = file_path.split('/')[-1]  # 添加文件名作为标识\n",
    "        sub_df_features.append(features)\n",
    "        \n",
    "    return sub_df_features\n",
    "\n",
    "# 定义批量提取特征的函数\n",
    "def extract_features_from_files(data_dir, output_file):\n",
    "    \"\"\"\n",
    "    从pkl文件中批量提取特征\n",
    "    :param data_dir: 存放pkl文件的目录\n",
    "    :param output_file: 保存特征的输出文件路径\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    file_names = [f for f in os.listdir(data_dir) if f.endswith('.pkl')][:]\n",
    "    file_paths = [os.path.join(data_dir, file_name) for file_name in file_names]\n",
    "    \n",
    "    results = Parallel(n_jobs=8)(delayed(process_file)(file_path) for file_path in tqdm(file_paths))\n",
    "    '''   \n",
    "    # 使用线程池并行处理文件\n",
    "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "        # 提交任务\n",
    "        futures = {executor.submit(process_file, file_path): file_path for file_path in file_paths}\n",
    "\n",
    "        # 使用 tqdm 显示进度条\n",
    "        for future in tqdm(as_completed(futures), total=len(file_paths), desc=\"Extracting features\"):\n",
    "            file_path = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                all_features.extend(result)\n",
    "            except Exception as e:\n",
    "                print(f\"文件 {file_path} 处理失败: {e}\")\n",
    "    '''\n",
    "    for result in results:\n",
    "        all_features.extend(result)\n",
    "    # 将特征保存为DataFrame并导出为CSV文件\n",
    "    df_features = pd.DataFrame(all_features)\n",
    "    df_features.to_csv(output_file, index=False)\n",
    "    print(f\"Features saved to {output_file}, shape is {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f4282a-6ef5-4f30-9efe-16c7e6a9fe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31839/31839 [08:43<00:00, 60.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to ../input/round2_train_X_extracted_features6.csv, shape is (1038194, 79)\n"
     ]
    }
   ],
   "source": [
    "data_directory = '../input/train_X'  # 替换为pkl文件所在的目录\n",
    "output_csv = '../input/round2_train_X_extracted_features6.csv'  # 输出文件路径\n",
    "extract_features_from_files(data_directory, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d530258e-fd84-4963-95fd-3f82daef9606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 315720/315720 [1:30:59<00:00, 57.83it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to ../input/round2_test_X_extracted_features6.csv, shape is (10138308, 79)\n"
     ]
    }
   ],
   "source": [
    "data_directory = '../input/test_X'  # 替换为pkl文件所在的目录\n",
    "output_csv = '../input/round2_test_X_extracted_features6.csv' # 输出文件路径\n",
    "extract_features_from_files(data_directory, output_csv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff8320a-fd7c-465b-8550-fdfb0891dc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b2501-4152-4dc8-86d4-95626a66c39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
